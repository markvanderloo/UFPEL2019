---
title: "Data Cleaning Tutorial: imputation"
author: "Mark van der Loo"
output:
  beamer_presentation:
    latex_engine: xelatex
    includes:
      in_header: ../tex/header.tex
classoption: "aspectratio=169"
---

## Try the code

\centering\huge

`03valid/impute.R`

## Imputing data

### Need to specify

- Imputation method
- Variable(s) to impute
- Variables used as predictor

### Simputation's goal

Easy to experiment, robust enough for production.

### Simputation interface

```{r, eval=FALSE}
impute_<model>(data, imputed_variables ~ predictors, ...)
```


## Imputing data with simputation



|  `<model>  `      |  description                                    |
|-------------------|-------------------------------------------------|
| `proxy`           | copy (transformation of) other variable(s)      |
| `median`          | (group-wise) median                             |
| `rlm`, `lm`, `en` | (robust) linear model, elasticnet regression    |
| `cart`, `rf`      | Classification And Regression Tree, RandomForest|
| `em`, `mf`        | EM-alogithm (multivariate normal) `missForest`  |
| `knn`             | $k$ nearest neighbours                          |
| `shd`, `rhd`      | sequential, random, hot-deck                    |
| `pmm`             | predictive mean matching                        |
| `impute_model`    | use pre-trained model                           |



## Imputation of the mean

```{r,echo=FALSE, fig.height=5.5}
library(magrittr)
library(simputation)
par(mfrow=c(1,2))
X <- rnorm(1000)
Y <- X + rnorm(1000,sd = 0.2)
i <- sample(1:1000,100,replace=FALSE)
Y[i] <- NA
plot(X,Y,pch=".",main="10% missing in Y", las=1)
d <- data.frame(X=X,Y=Y)
library(simputation)
d1 <- impute_lm(d,Y ~ X)
cols <- rep("black",1000)
cols[i] <- "red"
cex <- rep(1,1000)
cex[i] <- 4
plot(Y ~ X, data=d1, col=cols,pch=".",cex=cex,las=1,main="Imputation with model Y = a + bX")
```


## Adding a random residual

```{r, echo=FALSE, fig.height=5.5}
data("retailers", package="validate")
library(magrittr)
library(simputation)
ret <- retailers[3:10]
par(mfrow=c(1,2))
cols <- rep("black",1000)
cols[i] <- "red"
cex <- rep(1,1000)
cex[i] <- 3
plot(Y ~ X, data=d1, col=cols,pch=".",cex=cex,las=1,main="Imputation with model Y = a + bX")

d2 <- impute_lm(d,Y ~ X,add_residual = "normal")
plot(Y ~ X, data=d2, col=cols,pch=".",cex=cex,las=1,main="Imputation with Y = a + bX + e")
```




## Adding a random residual with `simputation`

### Example

```{r, echo=FALSE, results='hide'}
companies <- read.csv("data/errors_located.csv"
                      , stringsAsFactors=FALSE)
```

```{r, results='hide'}
impute_rlm(companies, other.rev ~ turnover
         , add_residual = "normal") 
```

### Options

-  "none"`: (default)
-  "normal"`: from $N(0,\hat{\sigma})$ 
-  "observed"`: from observed residuals

## Chaining methods

### Example

```{r, results='hide'}
companies %>%
  impute_lm(turnover ~ staff + profit) %>%
  impute_lm(turnover ~ staff)
```

## Assignment

1. Read `errors_located.csv` (`stringsAsFactors=FALSE`)
2. Make a separete data frame, selecting columns 7--14 (`staff`--`vat`)
3. Implement the following imputation sequence:
    - Impute `turnover` by copying the `vat` variable (`impute_proxy`)
    - Impute `staff` with a robust linear model based on `staff.costs`
    - Impute `staff` with a robust linear model based on `total.costs`
    - Impute `profit` as `total.rev - total.costs` (`impute_proxy`)
    - Impute everything else using `missForest` (formula: `. ~ .`)



# More on missing data and (s)imputation

## Missing data

\begin{center}
\includegraphics[height=0.8\textheight]{fig/missingvalue.pdf}
\end{center}

## Missing data

### Reasons

- nonresponse, data loss
- Value is observed but deemed wrong and erased

### Solutions

- Measure/observe again 
- Ignore
- Take into account when estimating
- **Impute**

## Missing data mechanisms

### Missing comletely at Random (MCAR)

Missingness is totally random.

### Missing at Random (MAR)

Missingness probability can be modeled by other variables

### Not Missing at Random (NMAR)

Missingness probability depends on missing value.


## You can't tell the mechanism from the data

### NMAR can look like MCAR

Given $Y,X$ independent. Remove all $y\geq y^*$. Observer
'sees' no correlation between missingness and values of $X$: MAR.


### NMAR can look like MAR

Given $Y,X$ with $\textsf{Cov}(Y,X)>0$. Remove all 
$y\geq y^*$. Observer 'sees' that higher $X$ correlates with
more missings in $Y$: MCAR.



## Dealing with missing data mechanisms

### Missing comletely at Random (MCAR)

Model-based imputation

### Missing at Random (MAR)

Model-based imputation

### Not Missing at Random (NMAR)

No real solution.


## Imputation methodology

### Model based

Estimate a value based on observed variables.

### Donor-imputation

Copy a value from a record that you did observe.


## The simputation package

### Provide

- a _uniform interface_,
- with _consistent behaviour_,
- across _commonly used methodologies_


### To facilitate

- experimentation 
- configuration for production



## The `simputation` package

### An imputation prodedure is specified by

1. The variable to impute
2. An imputation model
3. Predictor variables



### The simputation interface

```
impute_<model>(data
  , <imputed vars> ~ <predictor vars>
  , [options])
```

\begin{picture}(0,0)
\put(170,-20){\includegraphics[]{fig/simpute.pdf}}
\end{picture}


## Chaining methods

```{r}
ret %>% 
  impute_rlm(other.rev ~ turnover) %>%
  impute_rlm(other.rev ~ staff) %>% head(3)
```



## Example: Multiple variables, same predictors

```{r,eval=FALSE}
ret %>% 
  impute_rlm(other.rev + total.rev ~ turnover) 

ret %>% 
  impute_rlm( . - turnover ~ turnover) 
```

## Example: grouping

```{r, eval=FALSE}
retailers %>% impute_rlm(total.rev ~ turnover | size) 

# or, using dplyr::group_by
retailers %>% 
  group_by(size) %>%
  impute_rlm(total.rev ~ turnover)
```




## Imputation and univariate distribution

```{r,echo=FALSE,fig.height=5.5}
set.seed(1)
x <- rnorm(1000)
y <- x
i <- sample(1:1000,100,replace=FALSE)
x[i] <- NA
par(mfrow=c(3,1))
hist(y,main="true data",breaks=50,las=1)
hist(x,main="10% missing values", breaks=50,las=1)
x[i] <- mean(x,na.rm=TRUE)
hist(x,main="Imputating the mean",breaks=50,las=1)
```

## Imputation and bivariate distribution

```{r,echo=FALSE, fig.height=5.5}
par(mfrow=c(1,2))
X <- rnorm(1000)
Y <- X + rnorm(1000,sd = 0.2)
i <- sample(1:1000,100,replace=FALSE)
Y[i] <- NA
plot(X,Y,pch=".",main="10% missing in Y", las=1)
d <- data.frame(X=X,Y=Y)
library(simputation)
d1 <- impute_lm(d,Y ~ X)
cols <- rep("black",1000)
cols[i] <- "red"
cex <- rep(1,1000)
cex[i] <- 4
plot(Y ~ X, data=d1, col=cols,pch=".",cex=cex,las=1,main="Imputation with model Y = a + bX")
```

## Adding a random residual

$$
\hat{y}_i = \hat{f}(X_i) + \varepsilon_i
$$

- $\hat{y}_i$ estimated value for record $i$
- $\hat{f}(X_i)$ model value
- $\varepsilon_i$ random perturbation
    - Either a residual from the model training
    - OR sampled from $N(0,\hat{\sigma})$

\begin{itemize}
\item[$+$] Better (multivariate) distribution
\item[$-$] Less reproducible
\end{itemize}


## Adding a random residual


```{r, echo=FALSE, fig.height=5.5}
par(mfrow=c(1,2))
cols <- rep("black",1000)
cols[i] <- "red"
cex <- rep(1,1000)
cex[i] <- 3
plot(Y ~ X, data=d1, col=cols,pch=".",cex=cex,las=1,main="Imputation with model Y = a + bX")

d2 <- impute_lm(d,Y ~ X,add_residual = "normal")
plot(Y ~ X, data=d2, col=cols,pch=".",cex=cex,las=1,main="Imputation with Y = a + bX + e")
```

## Adding a residual with `simputation`

### Code

```{r, results='hide'}
ret %>%
  impute_rlm(other.rev ~ turnover
    , add_residual = "normal") %>% head(3)
```


### Options

- `add_residual = "none"`: (default)
- `add_residual = "normal"`: from $N(0,\hat{\sigma})$ 
- `add_residual = "observed"`: from observed residuals

Compute the variance of `other.rev` after each option.


# Ten models.

## 1. Impute a proxy

$$
\hat{\boldsymbol{y}} = \boldsymbol{x}\textrm{ or } \boldsymbol{y} = f(\boldsymbol{x}),
$$
where $\boldsymbol{x}$ is another (proxy) variable (e.g. VAT value for turnover),
and $f$ a user-defined (optional) transformation.

```{r,eval=FALSE}
# simputation
impute_proxy()
```

## 2. Linear model

$$
\hat{\boldsymbol{y}} = \boldsymbol{X}\hat{\boldsymbol{\beta}},
$$
where
$$
\hat{\boldsymbol{\beta}} 
=\arg\min_{\boldsymbol{\beta}}\sum_i\epsilon_i^2
%= \arg\min_{\boldsymbol{\beta}}\|\boldsymbol{Y}-\boldsymbol{X\beta}\|^2
$$
```{r,eval=FALSE}
# simputation:
impute_lm()
```


## 3. Regularized linear model (elasticnet)

$$
\hat{\boldsymbol{y}} = \boldsymbol{X}\hat{\boldsymbol{\beta}},
$$

where
$$
\hat{\boldsymbol{\beta}} = \arg\min_{\boldsymbol{\beta}}
\frac{1}{2}\sum_i\epsilon_i^2 + 
\lambda\left[
\frac{1-\alpha}{2}\|\boldsymbol{\beta}^*\|^2 + \alpha\|\boldsymbol{\beta}^*\|_1
\right]
$$

- $\alpha=0$ (Lasso) $\cdots$ $\alpha=1$ (Ridge)
- $\boldsymbol{\beta}^*$: $\boldsymbol{\beta}$ w/o intercept.

```{r,eval=FALSE}
# simputation:
impute_en()
```


## 4. $M$-estimator

$$
\hat{\boldsymbol{y}} = \boldsymbol{X}\hat{\boldsymbol{\beta}},
$$
where
$$
\hat{\boldsymbol{\beta}} = \arg\min_{\boldsymbol{\beta}}\sum_i\rho(\epsilon_i)
$$

```{r, eval=FALSE}
# simputation:
impute_rlm()
```

\begin{picture}(0,0)
\put(280,50){
\includegraphics[height=4cm]{fig/psifun.pdf}
}
\end{picture}

## 5. Classification and regression tree (CART)

$$
\hat{\boldsymbol{y}} = T(\boldsymbol{X}),
$$

where $T$ represents a set of binary questions on variables in $\boldsymbol{X}$.
There are spare questions for when one of the predictors is missing.


```{r,eval=FALSE}
# simputation:
impute_cart()
```

\begin{picture}(0,0)
\put(210,-30){
\includegraphics[height=3.5cm]{fig/rpart2.pdf}
}
\end{picture}

## 6. Random forest

$$
\hat{\boldsymbol{y}} = \frac{1}{|\textrm{Forest}|}\sum_{i\in\textrm{Forest}}T_i(\boldsymbol{X}),
$$
where each $T_i$ is a simple decision tree without spare questions. For categorical
$\boldsymbol{y}$, the majority vote is chosen.

```{r, eval=FALSE}
# simputation
impute_rf()
```

## 7. Expectation-Maximization

Dataset $\boldsymbol{X}=\boldsymbol{X}_{obs}\cup\boldsymbol{X}_{mis}$. Assume $\boldsymbol{X}\sim P(\boldsymbol{\theta})$.

1. Choose a $\hat{\boldsymbol{\theta}}$.
2. Repeat until convergence:
    a. $Q(\boldsymbol{\theta}|\hat{\boldsymbol{\theta}}) = \ell(\boldsymbol{\theta}|\boldsymbol{X}_{obs})+E_{mis}[\ell(\boldsymbol{X}_{mis}|\boldsymbol{\theta},\boldsymbol{X}_{obs})|\hat{\boldsymbol{\theta}}]$
    b. $\hat{\boldsymbol{\theta}}=\arg\max_{\boldsymbol{\theta}}Q(\boldsymbol{\theta}|\hat{\boldsymbol{\theta}})$
3. $\hat{\boldsymbol{X}}_{mis}=\arg\max_{\boldsymbol{X}_{mis}}P(\boldsymbol{X}_{mis}|\hat{\boldsymbol{\theta}})$

```{r, eval=FALSE}
# simputation (multivariate normal):
impute_em()
```

## 8. `missForest`

Dataset $\boldsymbol{X}=\boldsymbol{X}_{obs}\cup\boldsymbol{X}_{mis}$.

1. Trivial imputation of $\boldsymbol{X}_{mis}$ (median for numeric variables, mode for categorical variables)
2. Repeat until convergence:
    a. Train random forest models on the completed data
    b. Re-impute based on these models.
    
```{r, eval=FALSE}
# simputation:
impute_mf()
```

## 9.a Random hot deck

1. Split the data records into groups (optional)
2. Impute missing values by copying a value from a random record in the same group

```{r, eval=FALSE}
# simputation
impute_rhd(data, imputed_variables ~ grouping_variables)
```

## 9.b Sequential hot-deck

1. Sort the dataset
2. For each row in the sorted dataset, impute missing values from the last observed.

```{r,eval=FALSE}
# simputation
impute_shd(data, imputed_variables ~ sorting_variables)
```

## 9.c $k$-nearest neighbours

For each record with one or more missings:

1. Find the $k$ nearest neighbours (Gower's distance) with observed values
2. Sample value(s) from the $k$ records.

```{r,eval=FALSE}
# simputation
impute_knn(data, imputed_variables ~ distance_variables)
```

## 10. Predictive mean matching

1. For each variable $X_i$ with missing values, estimate a model $\hat{f}_i$.
2. Estimate all values, observed or not.
3. For each missing value, impute the observed value, of which the prediction
is closest to the prediction of the missing value.

```{r, eval=FALSE}
# simputation: (currently buggy!)
impute_pmm()
```

